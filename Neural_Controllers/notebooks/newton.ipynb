{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f5e166-38a4-4d7c-8b3f-2964ba367711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08d09bc-3783-4c4e-ab05-f90e9a90a173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_path = Path().absolute()\n",
    "sys.path.append(str(notebook_path.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4de4d92-4a29-4770-9622-082a8891d869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from neural_controllers import NeuralController\n",
    "from utils import newton_dataset\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77eb18-a0d1-4892-a81c-58c04bc67820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'llama'\n",
    "\n",
    "if model_type=='llama':\n",
    "    model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "    language_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, device_map=\"cuda\"\n",
    "    )\n",
    "\n",
    "    use_fast_tokenizer = \"LlamaForCausalLM\" not in language_model.config.architectures\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=use_fast_tokenizer, padding_side=\"left\", legacy=False)\n",
    "    tokenizer.pad_token_id = 0 if tokenizer.pad_token_id is None else tokenizer.pad_token_id\n",
    "    model_name='llama_3_8b_it'\n",
    "    \n",
    "elif model_type=='gemma':\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-9b-it\")\n",
    "    language_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"google/gemma-2-9b-it\",\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    model_name='gemma_2_9b_it'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce486a-15e8-4d73-89a3-634db0d77df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controller = NeuralController(\n",
    "        language_model,\n",
    "        tokenizer,\n",
    "        rfm_iters=8,\n",
    "        batch_size=4,\n",
    "        control_method='pca'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e2d56-b372-42a4-b116-fe8f7b4cc1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concept_types = [\"Cam\", \"Isaac\"]\n",
    "data_dir = \"../data/newton\"\n",
    "\n",
    "dataset = newton_dataset(data_dir, controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d5379-b316-4cb2-bfb2-bcf9f8c99dd6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "controllers = {}\n",
    "for concept_type in tqdm(concept_types):\n",
    "    \n",
    "    other_type = [k for k in concept_types if k != concept_type][0]\n",
    "    \n",
    "    train_data = dataset[concept_type]['train']\n",
    "    test_data = dataset[concept_type]['test']\n",
    "        \n",
    "    controller = NeuralController(\n",
    "        language_model,\n",
    "        tokenizer,\n",
    "        rfm_iters=8,\n",
    "        batch_size=4,\n",
    "        control_method='logistic'\n",
    "    )\n",
    "    \n",
    "    controller.compute_directions(train_data['inputs'], train_data['labels'])\n",
    "    \n",
    "    controllers[concept_type] = controller\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c8a53d6-d5ee-4287-a0d9-f6bd5cf9c45a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for concept_type in concept_types:\n",
    "    controller = controllers[concept_type]\n",
    "    other_type = [k for k in concept_types if k!=concept_type][0]\n",
    "    \n",
    "    controller.save(concept=f'{concept_type}', model_name='llama_3_8b_it', path='../directions/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37f8cb2-3e56-46dd-905c-0b15f0e9421c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd890e-cb3c-4067-bcaf-96ab626117e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_types = ['Cam', 'Isaac']\n",
    "controllers = {}\n",
    "\n",
    "for concept_type in concept_types:\n",
    "    \n",
    "    controller = NeuralController(\n",
    "        language_model,\n",
    "        tokenizer,\n",
    "        rfm_iters=8,\n",
    "        control_method='rfm'\n",
    "        # control_method='logistic'\n",
    "\n",
    "    )\n",
    "    \n",
    "    other_type = [k for k in concept_types if k!=concept_type][0]\n",
    "    \n",
    "    controller.load(concept=f'{concept_type}', model_name=model_name, path='../directions/')\n",
    "    \n",
    "    controllers[concept_type] = controller\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9130e73f-3f60-4709-8514-fb334ec190e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newton_type = \"Cam\"\n",
    "newton_type = \"Isaac\"\n",
    "\n",
    "raw_inputs = [\n",
    "    f\"What is Cam Newton known for?\",\n",
    "    # f\"Why is Newton the phycisist so famous?\",\n",
    "    # f\"Why is Isaac Newton so famous?\",\n",
    "    # f\"What did Newton contribute to motion?\",\n",
    "]\n",
    "inputs = [controller.format_prompt(x) for x in raw_inputs]\n",
    "\n",
    "num_new_tokens = 120\n",
    "controller = controllers[newton_type]\n",
    "\n",
    "coef=0.4 #llama \n",
    "# coef=9\n",
    "\n",
    "layers = list(range(-5, -31, -1))\n",
    "# layers = list(range(-1, -41, -1))\n",
    "\n",
    "gens=[]\n",
    "print()\n",
    "for i in inputs:\n",
    "    print(\"Prompt:\", i)\n",
    "    print(\"===== No Control =====\")\n",
    "    print(controller.generate(i, max_new_tokens=num_new_tokens, do_sample=False).replace(i, \"\"))\n",
    "    print()\n",
    "    \n",
    "    print(f\"===== + {newton_type} Control =====\")\n",
    "    gen = controller.generate(i, layers_to_control=layers, control_coef=coef, \n",
    "                                max_new_tokens=num_new_tokens, do_sample=False).replace(i, \"\")\n",
    "    gens.append(gen)\n",
    "    print(gen)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2dbcfb-a264-49ff-a001-90ea7c36b947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daniel_jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
