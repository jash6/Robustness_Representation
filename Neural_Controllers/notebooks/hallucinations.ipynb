{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f5e166-38a4-4d7c-8b3f-2964ba367711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f334bd-6d54-4a15-a0ed-3b21792af5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_path = Path().absolute()\n",
    "sys.path.append(str(notebook_path.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4de4d92-4a29-4770-9622-082a8891d869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import utils\n",
    "from neural_controllers import NeuralController\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f9df4-f467-4f29-87fa-d3a418691199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'llama'\n",
    "\n",
    "if model_type=='llama':\n",
    "\n",
    "    model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "    language_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, device_map=\"cuda\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    use_fast_tokenizer = \"LlamaForCausalLM\" not in language_model.config.architectures\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False, padding_side=\"left\")\n",
    "    tokenizer.pad_token_id = 0 \n",
    "    model_name='llama_3_8b_it'\n",
    "\n",
    "elif model_type=='gemma':\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-9b-it\")\n",
    "    language_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"google/gemma-2-9b-it\",\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    model_name='gemma_2_9b_it'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3af70-b07a-4c50-b76f-125666fa0a31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5066bc-1ac6-4911-b959-84e26552bb3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controller = NeuralController(\n",
    "    language_model,\n",
    "    tokenizer,\n",
    "    rfm_iters=8,\n",
    "    n_components=1,\n",
    "    control_method='logistic',\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5336711-5609-48a0-971a-1e11332c1a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path='../data/hallucinations/halu_eval/qa_data.txt'\n",
    "dataset = utils.hallucination_dataset(data_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec99a25-4061-4f8c-b2af-c000fd702932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controller.compute_directions(dataset['train']['inputs'], np.concatenate(dataset['train']['labels']).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b14e6e-1e25-45d8-a387-23160fa4843a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controller.save(concept='hallucination_halu_eval', model_name=model_name, path='../directions/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37f8cb2-3e56-46dd-905c-0b15f0e9421c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927d69e-557a-4b2f-8e8a-d38a60c9cd84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controller = NeuralController(\n",
    "    language_model,\n",
    "    tokenizer,\n",
    "    rfm_iters=8,\n",
    "    control_method='rfm',\n",
    "    n_components=1\n",
    ")\n",
    "controller.load(concept='hallucination_halu_eval', model_name=model_name, path='../directions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac8f4b94-0399-40ae-a728-b12707c43445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_inputs = [\n",
    "    f\"What is the percentage of forest fires that cause earthquakes?\",\n",
    "    # f\"What is the most popular food in the U.S.?\",\n",
    "    # f\"Based on percentages alone, which food is more popular in the U.S. burgers or pizza?\",\n",
    "    # f\"List the GDP of the top 10 countries in the middle east at the end of 2020\",\n",
    "    # f\"What is the speed of light?\",\n",
    "    # f\"How tall is Mount Everest?\",\n",
    "    # f\"Who painted the Mona Lisa?\",\n",
    "    # f\"What is the chemical formula for water?\",\n",
    "    # f\"What is the capital city of Australia?\",\n",
    "]\n",
    "\n",
    "inputs = []\n",
    "for x in raw_inputs:\n",
    "    inputs.append(controller.format_prompt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046c71c-ec1c-4164-a304-1810f86bfa80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_new_tokens = 200\n",
    "\n",
    "coef=0.6\n",
    "\n",
    "layers = list(range(-1, -31, -1))\n",
    "\n",
    "assistant_tag = '<|start_header_id|>assistant<|end_header_id|>'\n",
    "\n",
    "gens=[]\n",
    "print()\n",
    "for i in inputs:\n",
    "    print(\"Prompt:\", i)\n",
    "    print(\"===== No Control =====\")\n",
    "    normal_gen = controller.generate(i, max_new_tokens=num_new_tokens, do_sample=False)\n",
    "    start_idx = normal_gen.find(assistant_tag) + len(assistant_tag)\n",
    "    print(normal_gen[start_idx:])\n",
    "    print()\n",
    "    \n",
    "    print(f\"===== + Hallucination =====\")\n",
    "    gen = controller.generate(i, layers_to_control=layers, control_coef=coef, \n",
    "                                max_new_tokens=num_new_tokens, do_sample=False)\n",
    "    gens.append(gen)\n",
    "    start_idx = gen.find(assistant_tag) + len(assistant_tag)\n",
    "    print(gen[start_idx:])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ee6bf-fd30-4e22-83e9-8134e4d7b516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-daniel_jax]",
   "language": "python",
   "name": "conda-env-.conda-daniel_jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
