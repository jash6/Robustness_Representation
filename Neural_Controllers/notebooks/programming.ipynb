{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f5e166-38a4-4d7c-8b3f-2964ba367711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca061257-4ad9-47bf-bbe8-93d526ca9b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_path = Path().absolute()\n",
    "sys.path.append(str(notebook_path.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9d3f62-c301-43b0-801d-d8a5ceda91c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from neural_controllers import NeuralController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6438f5-0de8-48f5-843a-fac5dc46cb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import programming_language_dataset, pca_programming_language_dataset\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77eb18-a0d1-4892-a81c-58c04bc67820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'llama'\n",
    "\n",
    "if model_type=='llama':\n",
    "    model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "    language_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, device_map=\"cuda\"\n",
    "    )\n",
    "\n",
    "    use_fast_tokenizer = \"LlamaForCausalLM\" not in language_model.config.architectures\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=use_fast_tokenizer, padding_side=\"left\", legacy=False)\n",
    "    tokenizer.pad_token_id = 0 if tokenizer.pad_token_id is None else tokenizer.pad_token_id\n",
    "    model_name='llama_3_8b_it'\n",
    "    \n",
    "elif model_type=='gemma':\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-9b-it\")\n",
    "    language_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"google/gemma-2-9b-it\",\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    model_name='gemma_2_9b_it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e2d56-b372-42a4-b116-fe8f7b4cc1f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concept_types = ['python', 'c++']\n",
    "concept_types = ['python', 'javascript']\n",
    "data_dir = \"../data/programming\"\n",
    "\n",
    "dataset = programming_language_dataset(concept_types, tokenizer)\n",
    "# dataset = pca_programming_language_dataset(concept_types, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c921a75-6641-4e17-9c51-162e0a1caa59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controllers = {}\n",
    "for concept_type in tqdm(concept_types):\n",
    "    \n",
    "    other_type = [k for k in concept_types if k != concept_type][0]\n",
    "    \n",
    "    train_data = dataset[concept_type]['train']\n",
    "    test_data = dataset[concept_type]['test']\n",
    "        \n",
    "    language_controller = NeuralController(\n",
    "        language_model,\n",
    "        tokenizer,\n",
    "        rfm_iters=8,\n",
    "        batch_size=2,\n",
    "    )\n",
    "    \n",
    "    language_controller.compute_directions(train_data['inputs'], train_data['labels'])\n",
    "    \n",
    "    controllers[concept_type] = language_controller\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab3cd2e-3b64-4e31-a980-aa0c32b25f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for concept_type in concept_types:\n",
    "    try:\n",
    "        controller = controllers[concept_type]\n",
    "        other_type = [k for k in concept_types if k!=concept_type][0]\n",
    "        controller.save(concept=f'{concept_type}_{other_type}', model_name=model_name, path='../directions/')\n",
    "    except:\n",
    "        print(f'{concept_type} not found')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37f8cb2-3e56-46dd-905c-0b15f0e9421c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37229855-01cc-4770-a524-6d5432120786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "huggingface_dataset = load_dataset(\"greengerong/leetcode\")\n",
    "python_dataset = huggingface_dataset[\"train\"]['python']\n",
    "js_dataset = huggingface_dataset[\"train\"]['javascript']\n",
    "\n",
    "\n",
    "def extract_code(c):\n",
    "    items = c.split(\"```\")\n",
    "    code = items[1]\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311a72e-dc35-4e36-b77c-e805e598aa29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concept_types = ['python', 'javascript']\n",
    "controllers = {}\n",
    "\n",
    "for concept_type in concept_types:\n",
    "    \n",
    "    controller = NeuralController(\n",
    "        language_model,\n",
    "        tokenizer,\n",
    "        control_method='rfm',\n",
    "        n_components=1\n",
    "    )\n",
    "    \n",
    "    other_type = [k for k in concept_types if k!=concept_type][0]\n",
    "    \n",
    "    try:\n",
    "        controller.load(\n",
    "                        concept=f'{concept_type}_{other_type}', \n",
    "                        model_name=model_name, \n",
    "                        path='../directions/')\n",
    "        controllers[concept_type] = controller\n",
    "    except:\n",
    "        print(f'{concept_type} not found')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9130e73f-3f60-4709-8514-fb334ec190e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concept_type = \"javascript\"\n",
    "# concept_type = \"python\"\n",
    "\n",
    "idx=0\n",
    "js_task = extract_code(js_dataset[idx])\n",
    "python_task = extract_code(python_dataset[idx])\n",
    "prompt = f\"Re-state the following program. \"\n",
    "# prompt = f\"Give a single, different re-writing of this program with the same function. \"\n",
    "# prompt += f\"The output will be judged by an expert in all programming languages. \"\n",
    "# prompt += f\"Do not include an explanation.\\n\\n```{python_task}```\"\n",
    "prompt += f\"Do not include an explanation.\\n\\n```{js_task}```\"\n",
    "\n",
    "# prompt = f\"Re-state the following program. Do not include an explanation. {python_task}.\"\n",
    "# prompt = f\"Give a single, different re-writing of this program with the same function. \"\n",
    "# prompt += f\"The output will be judged by an expert in all programming languages. \"\n",
    "# # prompt += f\"Do not include an explanation.\\n\\n```{python_task}```\"\n",
    "\n",
    "\n",
    "\n",
    "layer_id = list(range(-1, -31, -1))\n",
    "# layer_id = list(range(-1, -41, -1))\n",
    "language_controller = controllers[concept_type]\n",
    "num_new_tokens = 150\n",
    "\n",
    "inputs = language_controller.format_prompt(prompt)\n",
    "\n",
    "\n",
    "# rfm\n",
    "# coeff=9 # for javascript, gemma\n",
    "coeff=0.7 # for javascript, llama\n",
    "\n",
    "print(inputs)\n",
    "print(\"===== No Control =====\")\n",
    "gen1 = language_controller.generate(inputs, max_new_tokens=num_new_tokens, do_sample=False)\n",
    "print(gen1[len(inputs):])\n",
    "print()\n",
    "print(f\"===== + {concept_type} Control =====\")\n",
    "gen2 = language_controller.generate(inputs, layers_to_control=layer_id, control_coef=coeff, \n",
    "                            max_new_tokens=num_new_tokens, do_sample=False)\n",
    "print(gen2[len(inputs):])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a83b0db-a937-49b2-9bb3-d8650fe5fd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-daniel_jax]",
   "language": "python",
   "name": "conda-env-.conda-daniel_jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
