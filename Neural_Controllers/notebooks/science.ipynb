{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f5e166-38a4-4d7c-8b3f-2964ba367711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35a98ec-024c-46f0-bc78-86f13c278ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "notebook_path = Path().absolute()\n",
    "sys.path.append(str(notebook_path.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9d3f62-c301-43b0-801d-d8a5ceda91c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from neural_controllers import NeuralController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6438f5-0de8-48f5-843a-fac5dc46cb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import concept_dataset, multi_concept_dataset\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b77eb18-a0d1-4892-a81c-58c04bc67820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570e9bf8f81d4f65a2d8525a2f390cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: [128000, 15339] !\n"
     ]
    }
   ],
   "source": [
    "model_type = 'llama'\n",
    "\n",
    "if model_type=='llama':\n",
    "\n",
    "    # model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "    model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "    language_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, device_map=\"cuda\"\n",
    "    )\n",
    "\n",
    "    use_fast_tokenizer = \"LlamaForCausalLM\" not in language_model.config.architectures\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=use_fast_tokenizer, padding_side=\"left\", legacy=False)\n",
    "    tokenizer.pad_token_id = 0 if tokenizer.pad_token_id is None else tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59a8c2a2-30b9-4543-8fda-a2fa293f7372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Controller hyperparameters:\n",
      "control_method       : rfm\n",
      "rfm_iters            : 8\n",
      "forward_batch_size   : 8\n",
      "M_batch_size         : 2048\n",
      "n_components         : 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "controller = NeuralController(\n",
    "        language_model,\n",
    "        tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279e2d56-b372-42a4-b116-fe8f7b4cc1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 300 test 122\n",
      "train 300 test 122\n"
     ]
    }
   ],
   "source": [
    "concept_types = ['Biology', 'Classical Mechanics']#, 'Geology', 'Chemistry']\n",
    "data_dir = \"../data/science_subjects\"\n",
    "\n",
    "dataset = concept_dataset(data_dir, concept_types, controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2dbcfb-a264-49ff-a001-90ea7c36b947",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Controller hyperparameters:\n",
      "control_method       : pca\n",
      "rfm_iters            : 8\n",
      "forward_batch_size   : 4\n",
      "M_batch_size         : 2048\n",
      "n_components         : 5\n",
      "\n",
      "train_y torch.Size([240, 1]) val_y torch.Size([60, 1])\n",
      "Getting activations from forward passes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/75 [00:00<00:37,  1.98it/s]\u001b[A\n",
      "  3%|▎         | 2/75 [00:01<00:37,  1.94it/s]\u001b[A\n",
      "  4%|▍         | 3/75 [00:01<00:37,  1.93it/s]\u001b[A\n",
      "  5%|▌         | 4/75 [00:02<00:36,  1.93it/s]\u001b[A\n",
      "  7%|▋         | 5/75 [00:02<00:36,  1.93it/s]\u001b[A\n",
      "  8%|▊         | 6/75 [00:03<00:35,  1.92it/s]\u001b[A\n",
      "  9%|▉         | 7/75 [00:03<00:35,  1.92it/s]\u001b[A\n",
      " 11%|█         | 8/75 [00:04<00:34,  1.91it/s]\u001b[A\n",
      " 12%|█▏        | 9/75 [00:04<00:34,  1.92it/s]\u001b[A\n",
      " 13%|█▎        | 10/75 [00:05<00:33,  1.92it/s]\u001b[A\n",
      " 15%|█▍        | 11/75 [00:05<00:33,  1.92it/s]\u001b[A\n",
      " 16%|█▌        | 12/75 [00:06<00:32,  1.92it/s]\u001b[A\n",
      " 17%|█▋        | 13/75 [00:06<00:32,  1.92it/s]\u001b[A\n",
      " 19%|█▊        | 14/75 [00:07<00:31,  1.92it/s]\u001b[A\n",
      " 20%|██        | 15/75 [00:07<00:31,  1.93it/s]\u001b[A\n",
      " 21%|██▏       | 16/75 [00:08<00:30,  1.92it/s]\u001b[A\n",
      " 23%|██▎       | 17/75 [00:08<00:30,  1.92it/s]\u001b[A\n",
      " 24%|██▍       | 18/75 [00:09<00:29,  1.92it/s]\u001b[A\n",
      " 25%|██▌       | 19/75 [00:09<00:29,  1.93it/s]\u001b[A\n",
      " 27%|██▋       | 20/75 [00:10<00:28,  1.93it/s]\u001b[A\n",
      " 28%|██▊       | 21/75 [00:10<00:28,  1.92it/s]\u001b[A\n",
      " 29%|██▉       | 22/75 [00:11<00:27,  1.92it/s]\u001b[A\n",
      " 31%|███       | 23/75 [00:11<00:27,  1.92it/s]\u001b[A\n",
      " 32%|███▏      | 24/75 [00:12<00:26,  1.92it/s]\u001b[A\n",
      " 33%|███▎      | 25/75 [00:13<00:26,  1.92it/s]\u001b[A\n",
      " 35%|███▍      | 26/75 [00:13<00:25,  1.92it/s]\u001b[A\n",
      " 36%|███▌      | 27/75 [00:14<00:25,  1.92it/s]\u001b[A\n",
      " 37%|███▋      | 28/75 [00:14<00:24,  1.92it/s]\u001b[A\n",
      " 39%|███▊      | 29/75 [00:15<00:23,  1.92it/s]\u001b[A\n",
      " 40%|████      | 30/75 [00:15<00:23,  1.92it/s]\u001b[A\n",
      " 41%|████▏     | 31/75 [00:16<00:22,  1.91it/s]\u001b[A\n",
      " 43%|████▎     | 32/75 [00:16<00:22,  1.91it/s]\u001b[A\n",
      " 44%|████▍     | 33/75 [00:17<00:21,  1.91it/s]\u001b[A\n",
      " 45%|████▌     | 34/75 [00:17<00:21,  1.91it/s]\u001b[A\n",
      " 47%|████▋     | 35/75 [00:18<00:20,  1.91it/s]\u001b[A\n",
      " 48%|████▊     | 36/75 [00:18<00:20,  1.91it/s]\u001b[A\n",
      " 49%|████▉     | 37/75 [00:19<00:19,  1.91it/s]\u001b[A\n",
      " 51%|█████     | 38/75 [00:19<00:19,  1.91it/s]\u001b[A\n",
      " 52%|█████▏    | 39/75 [00:20<00:18,  1.91it/s]\u001b[A\n",
      " 53%|█████▎    | 40/75 [00:20<00:18,  1.91it/s]\u001b[A\n",
      " 55%|█████▍    | 41/75 [00:21<00:17,  1.91it/s]\u001b[A\n",
      " 56%|█████▌    | 42/75 [00:21<00:17,  1.91it/s]\u001b[A\n",
      " 57%|█████▋    | 43/75 [00:22<00:16,  1.91it/s]\u001b[A\n",
      " 59%|█████▊    | 44/75 [00:22<00:16,  1.91it/s]\u001b[A\n",
      " 60%|██████    | 45/75 [00:23<00:15,  1.91it/s]\u001b[A\n",
      " 61%|██████▏   | 46/75 [00:23<00:15,  1.91it/s]\u001b[A\n",
      " 63%|██████▎   | 47/75 [00:24<00:14,  1.91it/s]\u001b[A\n",
      " 64%|██████▍   | 48/75 [00:25<00:14,  1.91it/s]\u001b[A\n",
      " 65%|██████▌   | 49/75 [00:25<00:13,  1.91it/s]\u001b[A\n",
      " 67%|██████▋   | 50/75 [00:26<00:13,  1.91it/s]\u001b[A\n",
      " 68%|██████▊   | 51/75 [00:26<00:12,  1.91it/s]\u001b[A\n",
      " 69%|██████▉   | 52/75 [00:27<00:12,  1.91it/s]\u001b[A\n",
      " 71%|███████   | 53/75 [00:27<00:11,  1.91it/s]\u001b[A\n",
      " 72%|███████▏  | 54/75 [00:28<00:11,  1.91it/s]\u001b[A\n",
      " 73%|███████▎  | 55/75 [00:28<00:10,  1.90it/s]\u001b[A\n",
      " 75%|███████▍  | 56/75 [00:29<00:09,  1.91it/s]\u001b[A\n",
      " 76%|███████▌  | 57/75 [00:29<00:09,  1.90it/s]\u001b[A\n",
      " 77%|███████▋  | 58/75 [00:30<00:08,  1.90it/s]\u001b[A\n",
      " 79%|███████▊  | 59/75 [00:30<00:08,  1.90it/s]\u001b[A\n",
      " 80%|████████  | 60/75 [00:31<00:07,  1.91it/s]\u001b[A\n",
      " 81%|████████▏ | 61/75 [00:31<00:07,  1.91it/s]\u001b[A\n",
      " 83%|████████▎ | 62/75 [00:32<00:06,  1.91it/s]\u001b[A\n",
      " 84%|████████▍ | 63/75 [00:32<00:06,  1.91it/s]\u001b[A\n",
      " 85%|████████▌ | 64/75 [00:33<00:05,  1.91it/s]\u001b[A\n",
      " 87%|████████▋ | 65/75 [00:33<00:05,  1.91it/s]\u001b[A\n",
      " 88%|████████▊ | 66/75 [00:34<00:04,  1.91it/s]\u001b[A\n",
      " 89%|████████▉ | 67/75 [00:35<00:04,  1.90it/s]\u001b[A\n",
      " 91%|█████████ | 68/75 [00:35<00:03,  1.90it/s]\u001b[A\n",
      " 92%|█████████▏| 69/75 [00:36<00:03,  1.90it/s]\u001b[A\n",
      " 93%|█████████▎| 70/75 [00:36<00:02,  1.90it/s]\u001b[A\n",
      " 95%|█████████▍| 71/75 [00:37<00:02,  1.90it/s]\u001b[A\n",
      " 96%|█████████▌| 72/75 [00:37<00:01,  1.90it/s]\u001b[A\n",
      " 97%|█████████▋| 73/75 [00:38<00:01,  1.90it/s]\u001b[A\n",
      " 99%|█████████▊| 74/75 [00:38<00:00,  1.90it/s]\u001b[A\n",
      "100%|██████████| 75/75 [00:39<00:00,  1.91it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/31 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 1/31 [00:00<00:08,  3.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▋         | 2/31 [00:00<00:07,  3.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 3/31 [00:00<00:07,  3.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 4/31 [00:01<00:06,  3.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 5/31 [00:01<00:06,  3.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 6/31 [00:01<00:06,  3.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 7/31 [00:01<00:06,  3.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 8/31 [00:02<00:05,  3.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 9/31 [00:02<00:05,  3.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 10/31 [00:02<00:05,  3.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 11/31 [00:02<00:05,  3.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▊      | 12/31 [00:03<00:04,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 13/31 [00:03<00:04,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 14/31 [00:03<00:04,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 15/31 [00:03<00:04,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 16/31 [00:04<00:03,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▍    | 17/31 [00:04<00:03,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 18/31 [00:04<00:03,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████▏   | 19/31 [00:04<00:03,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▍   | 20/31 [00:05<00:02,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 21/31 [00:05<00:02,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 22/31 [00:05<00:02,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████▍  | 23/31 [00:05<00:02,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|███████▋  | 24/31 [00:06<00:01,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████  | 25/31 [00:06<00:01,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 26/31 [00:06<00:01,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 27/31 [00:06<00:01,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 28/31 [00:07<00:00,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▎| 29/31 [00:07<00:00,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 30/31 [00:07<00:00,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 31/31 [00:07<00:00,  3.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signs\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 31/31 [00:00<00:00, 68146.45it/s]\n",
      " 50%|█████     | 1/2 [00:47<00:47, 47.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Controller hyperparameters:\n",
      "control_method       : pca\n",
      "rfm_iters            : 8\n",
      "forward_batch_size   : 4\n",
      "M_batch_size         : 2048\n",
      "n_components         : 5\n",
      "\n",
      "train_y torch.Size([240, 1]) val_y torch.Size([60, 1])\n",
      "Getting activations from forward passes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏         | 1/75 [00:00<00:38,  1.94it/s]\u001b[A\n",
      "  3%|▎         | 2/75 [00:01<00:38,  1.91it/s]\u001b[A\n",
      "  4%|▍         | 3/75 [00:01<00:37,  1.91it/s]\u001b[A\n",
      "  5%|▌         | 4/75 [00:02<00:37,  1.90it/s]\u001b[A\n",
      "  7%|▋         | 5/75 [00:02<00:36,  1.90it/s]\u001b[A\n",
      "  8%|▊         | 6/75 [00:03<00:36,  1.90it/s]\u001b[A\n",
      "  9%|▉         | 7/75 [00:03<00:35,  1.90it/s]\u001b[A\n",
      " 11%|█         | 8/75 [00:04<00:35,  1.90it/s]\u001b[A\n",
      " 12%|█▏        | 9/75 [00:04<00:34,  1.90it/s]\u001b[A\n",
      " 13%|█▎        | 10/75 [00:05<00:34,  1.90it/s]\u001b[A\n",
      " 15%|█▍        | 11/75 [00:05<00:33,  1.90it/s]\u001b[A\n",
      " 16%|█▌        | 12/75 [00:06<00:33,  1.90it/s]\u001b[A\n",
      " 17%|█▋        | 13/75 [00:06<00:32,  1.89it/s]\u001b[A\n",
      " 19%|█▊        | 14/75 [00:07<00:32,  1.89it/s]\u001b[A\n",
      " 20%|██        | 15/75 [00:07<00:31,  1.89it/s]\u001b[A\n",
      " 21%|██▏       | 16/75 [00:08<00:31,  1.89it/s]\u001b[A\n",
      " 23%|██▎       | 17/75 [00:08<00:30,  1.89it/s]\u001b[A\n",
      " 24%|██▍       | 18/75 [00:09<00:30,  1.89it/s]\u001b[A\n",
      " 25%|██▌       | 19/75 [00:10<00:29,  1.89it/s]\u001b[A\n",
      " 27%|██▋       | 20/75 [00:10<00:29,  1.89it/s]\u001b[A\n",
      " 28%|██▊       | 21/75 [00:11<00:28,  1.89it/s]\u001b[A\n",
      " 29%|██▉       | 22/75 [00:11<00:28,  1.89it/s]\u001b[A\n",
      " 31%|███       | 23/75 [00:12<00:27,  1.89it/s]\u001b[A\n",
      " 32%|███▏      | 24/75 [00:12<00:27,  1.89it/s]\u001b[A\n",
      " 33%|███▎      | 25/75 [00:13<00:26,  1.89it/s]\u001b[A\n",
      " 35%|███▍      | 26/75 [00:13<00:25,  1.89it/s]\u001b[A\n",
      " 36%|███▌      | 27/75 [00:14<00:25,  1.89it/s]\u001b[A\n",
      " 37%|███▋      | 28/75 [00:14<00:24,  1.89it/s]\u001b[A\n",
      " 39%|███▊      | 29/75 [00:15<00:24,  1.90it/s]\u001b[A\n",
      " 40%|████      | 30/75 [00:15<00:23,  1.90it/s]\u001b[A\n",
      " 41%|████▏     | 31/75 [00:16<00:23,  1.90it/s]\u001b[A\n",
      " 43%|████▎     | 32/75 [00:16<00:22,  1.90it/s]\u001b[A\n",
      " 44%|████▍     | 33/75 [00:17<00:22,  1.90it/s]\u001b[A\n",
      " 45%|████▌     | 34/75 [00:17<00:21,  1.90it/s]\u001b[A\n",
      " 47%|████▋     | 35/75 [00:18<00:21,  1.90it/s]\u001b[A\n",
      " 48%|████▊     | 36/75 [00:19<00:20,  1.89it/s]\u001b[A\n",
      " 49%|████▉     | 37/75 [00:19<00:20,  1.90it/s]\u001b[A\n",
      " 51%|█████     | 38/75 [00:20<00:19,  1.90it/s]\u001b[A\n",
      " 52%|█████▏    | 39/75 [00:20<00:18,  1.90it/s]\u001b[A\n",
      " 53%|█████▎    | 40/75 [00:21<00:18,  1.90it/s]\u001b[A\n",
      " 55%|█████▍    | 41/75 [00:21<00:17,  1.89it/s]\u001b[A\n",
      " 56%|█████▌    | 42/75 [00:22<00:17,  1.90it/s]\u001b[A\n",
      " 57%|█████▋    | 43/75 [00:22<00:16,  1.89it/s]\u001b[A\n",
      " 59%|█████▊    | 44/75 [00:23<00:16,  1.89it/s]\u001b[A\n",
      " 60%|██████    | 45/75 [00:23<00:15,  1.89it/s]\u001b[A\n",
      " 61%|██████▏   | 46/75 [00:24<00:15,  1.89it/s]\u001b[A\n",
      " 63%|██████▎   | 47/75 [00:24<00:14,  1.89it/s]\u001b[A\n",
      " 64%|██████▍   | 48/75 [00:25<00:14,  1.89it/s]\u001b[A\n",
      " 65%|██████▌   | 49/75 [00:25<00:13,  1.89it/s]\u001b[A\n",
      " 67%|██████▋   | 50/75 [00:26<00:13,  1.89it/s]\u001b[A\n",
      " 68%|██████▊   | 51/75 [00:26<00:12,  1.89it/s]\u001b[A\n",
      " 69%|██████▉   | 52/75 [00:27<00:12,  1.89it/s]\u001b[A\n",
      " 71%|███████   | 53/75 [00:27<00:11,  1.89it/s]\u001b[A\n",
      " 72%|███████▏  | 54/75 [00:28<00:11,  1.89it/s]\u001b[A\n",
      " 73%|███████▎  | 55/75 [00:29<00:10,  1.89it/s]\u001b[A\n",
      " 75%|███████▍  | 56/75 [00:29<00:10,  1.89it/s]\u001b[A\n",
      " 76%|███████▌  | 57/75 [00:30<00:09,  1.89it/s]\u001b[A\n",
      " 77%|███████▋  | 58/75 [00:30<00:09,  1.89it/s]\u001b[A\n",
      " 79%|███████▊  | 59/75 [00:31<00:08,  1.88it/s]\u001b[A\n",
      " 80%|████████  | 60/75 [00:31<00:07,  1.88it/s]\u001b[A\n",
      " 81%|████████▏ | 61/75 [00:32<00:07,  1.88it/s]\u001b[A\n",
      " 83%|████████▎ | 62/75 [00:32<00:06,  1.88it/s]\u001b[A\n",
      " 84%|████████▍ | 63/75 [00:33<00:06,  1.88it/s]\u001b[A\n",
      " 85%|████████▌ | 64/75 [00:33<00:05,  1.88it/s]\u001b[A\n",
      " 87%|████████▋ | 65/75 [00:34<00:05,  1.88it/s]\u001b[A\n",
      " 88%|████████▊ | 66/75 [00:34<00:04,  1.88it/s]\u001b[A\n",
      " 89%|████████▉ | 67/75 [00:35<00:04,  1.88it/s]\u001b[A\n",
      " 91%|█████████ | 68/75 [00:35<00:03,  1.88it/s]\u001b[A\n",
      " 92%|█████████▏| 69/75 [00:36<00:03,  1.88it/s]\u001b[A\n",
      " 93%|█████████▎| 70/75 [00:37<00:02,  1.88it/s]\u001b[A\n",
      " 95%|█████████▍| 71/75 [00:37<00:02,  1.88it/s]\u001b[A\n",
      " 96%|█████████▌| 72/75 [00:38<00:01,  1.88it/s]\u001b[A\n",
      " 97%|█████████▋| 73/75 [00:38<00:01,  1.88it/s]\u001b[A\n",
      " 99%|█████████▊| 74/75 [00:39<00:00,  1.88it/s]\u001b[A\n",
      "100%|██████████| 75/75 [00:39<00:00,  1.89it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/31 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 1/31 [00:00<00:07,  3.98it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▋         | 2/31 [00:00<00:07,  3.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 3/31 [00:00<00:07,  3.93it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 4/31 [00:01<00:06,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 5/31 [00:01<00:06,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 6/31 [00:01<00:06,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 7/31 [00:01<00:06,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 8/31 [00:02<00:05,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 9/31 [00:02<00:05,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 10/31 [00:02<00:05,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 11/31 [00:02<00:05,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▊      | 12/31 [00:03<00:04,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 13/31 [00:03<00:04,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 14/31 [00:03<00:04,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 15/31 [00:03<00:04,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 16/31 [00:04<00:03,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▍    | 17/31 [00:04<00:03,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 18/31 [00:04<00:03,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████▏   | 19/31 [00:04<00:03,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▍   | 20/31 [00:05<00:02,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 21/31 [00:05<00:02,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 22/31 [00:05<00:02,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████▍  | 23/31 [00:05<00:02,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|███████▋  | 24/31 [00:06<00:01,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████  | 25/31 [00:06<00:01,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 26/31 [00:06<00:01,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 27/31 [00:06<00:01,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 28/31 [00:07<00:00,  3.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▎| 29/31 [00:07<00:00,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 30/31 [00:07<00:00,  3.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 1])\n",
      "Training PCA model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 31/31 [00:07<00:00,  3.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signs\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n",
      "hidden_state_projections torch.Size([300]) all_y torch.Size([300, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 31/31 [00:00<00:00, 68505.49it/s]\n",
      "100%|██████████| 2/2 [01:35<00:00, 47.52s/it]\n"
     ]
    }
   ],
   "source": [
    "controllers = {}\n",
    "for concept_type in tqdm(concept_types):\n",
    "    \n",
    "    other_type = [k for k in concept_types if k != concept_type][0]\n",
    "    \n",
    "    train_data = dataset[concept_type]['train']\n",
    "    test_data = dataset[concept_type]['test']\n",
    "        \n",
    "    controller = NeuralController(\n",
    "        language_model,\n",
    "        tokenizer,\n",
    "        rfm_iters=8,\n",
    "        batch_size=4,\n",
    "        control_method='pca'\n",
    "    )\n",
    "    \n",
    "    controller.compute_directions(train_data['inputs'], train_data['labels']) \n",
    "                                           # log_path=f'../agop_spectra/{concept_type}', log_spectrum=True)\n",
    "    \n",
    "    controllers[concept_type] = controller\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a88d8fe-fcbb-488e-b963-6957d12d9584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept_type Biology\n",
      "concept_type Classical Mechanics\n"
     ]
    }
   ],
   "source": [
    "for concept_type in concept_types:\n",
    "    controller = controllers[concept_type]\n",
    "    # other_type = [k for k in concept_types if k!=concept_type][0]\n",
    "    print(\"concept_type\", concept_type)\n",
    "    # print(\"Other type\", other_type)\n",
    "    \n",
    "    controller.save(concept=f\"{concept_type.replace(' ', '-')}\", model_name='llama_3_8b_it', path='../directions/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55986ff5-e6f9-488d-a6d3-1b5a305d4a8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Multi-concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36bff14a-3d4e-4060-8eff-89aef1aea7d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Controller hyperparameters:\n",
      "control_method       : rfm\n",
      "rfm_iters            : 8\n",
      "forward_batch_size   : 4\n",
      "M_batch_size         : 2048\n",
      "n_components         : 1\n",
      "\n",
      "Getting activations from forward passes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:33<00:00,  2.27it/s]\n",
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.0020981610286980867, R2: None, reg: 0.001, bw: 1000, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/31 [00:02<01:25,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-1.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.002401650184765458, R2: None, reg: 0.001, bw: 1000, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2/31 [00:05<01:20,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-2.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.002959304256364703, R2: None, reg: 0.001, bw: 1000, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3/31 [00:08<01:19,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-3.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.0029589904006570578, R2: None, reg: 0.001, bw: 1000, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/31 [00:11<01:14,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-4.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.003636735724285245, R2: None, reg: 0.001, bw: 100, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5/31 [00:14<01:15,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-5.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.004714768845587969, R2: None, reg: 0.001, bw: 100, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6/31 [00:17<01:12,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-6.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.005513761192560196, R2: None, reg: 0.001, bw: 1000, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/31 [00:20<01:11,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-7.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.005704257171601057, R2: None, reg: 0.001, bw: 100, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 8/31 [00:23<01:07,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-8.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.005211944691836834, R2: None, reg: 0.001, bw: 1000, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 9/31 [00:26<01:05,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-9.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.006502476986497641, R2: None, reg: 0.001, bw: 100, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 10/31 [00:29<01:01,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-10.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.006231639068573713, R2: None, reg: 0.001, bw: 1000, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 11/31 [00:32<00:58,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-11.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.00794919766485691, R2: None, reg: 0.001, bw: 100, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 12/31 [00:34<00:54,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-12.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.008004785515367985, R2: None, reg: 0.01, bw: 100, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 13/31 [00:37<00:51,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-13.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.0074312458746135235, R2: None, reg: 0.001, bw: 100, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 14/31 [00:40<00:48,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-14.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.008539503440260887, R2: None, reg: 0.001, bw: 100, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 15/31 [00:43<00:45,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-15.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.008295046165585518, R2: None, reg: 0.001, bw: 100, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 16/31 [00:46<00:46,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-16.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.010946803726255894, R2: None, reg: 0.001, bw: 100, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 17/31 [00:49<00:42,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-17.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.014955594204366207, R2: None, reg: 0.001, bw: 100, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 18/31 [00:52<00:39,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-18.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.012817835435271263, R2: None, reg: 0.001, bw: 100, acc: 96.66667175292969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 19/31 [00:55<00:36,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-19.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.01776823401451111, R2: None, reg: 0.001, bw: 100, acc: 96.66667175292969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 20/31 [00:58<00:33,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-20.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.018211757764220238, R2: None, reg: 0.001, bw: 100, acc: 96.66667175292969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 21/31 [01:02<00:31,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-21.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.011796312406659126, R2: None, reg: 0.001, bw: 5, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 22/31 [01:05<00:27,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-22.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.005552544258534908, R2: None, reg: 0.001, bw: 5, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 23/31 [01:08<00:24,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-23.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.005343331489712, R2: None, reg: 0.01, bw: 5, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 24/31 [01:11<00:20,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-24.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.004615167621523142, R2: None, reg: 0.01, bw: 5, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [01:14<00:17,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-25.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.0063772243447601795, R2: None, reg: 0.001, bw: 5, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 26/31 [01:16<00:14,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-26.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.0036815761122852564, R2: None, reg: 0.001, bw: 10, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 27/31 [01:19<00:11,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-27.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.003232859540730715, R2: None, reg: 0.001, bw: 10, acc: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 28/31 [01:22<00:08,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-28.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.00330732180736959, R2: None, reg: 0.001, bw: 10, acc: 98.33334350585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 29/31 [01:25<00:05,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-29.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.01613503508269787, R2: None, reg: 0.01, bw: 0.2, acc: 95.00000762939453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 30/31 [01:28<00:02,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-30.pt\n",
      "train X shape: torch.Size([240, 4096]) train y shape: torch.Size([240, 4]) val X shape: torch.Size([60, 4096]) val y shape: torch.Size([60, 4])\n",
      "Best RFM loss: 0.01888142339885235, R2: None, reg: 0.001, bw: 5, acc: 96.66667175292969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:30<00:00,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum_filename ../agop_spectra/multi_science_layer_-31.pt\n",
      "Computing signs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'signs' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m test_data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m language_controller \u001b[38;5;241m=\u001b[39m NeuralController(\n\u001b[1;32m      5\u001b[0m     language_model,\n\u001b[1;32m      6\u001b[0m     tokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     control_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrfm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m language_controller\u001b[38;5;241m.\u001b[39mcompute_directions(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m], train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     13\u001b[0m                                        log_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../agop_spectra/multi_science\u001b[39m\u001b[38;5;124m'\u001b[39m, log_spectrum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/mech_interp/neural_control/neural_controllers.py:111\u001b[0m, in \u001b[0;36mNeuralController.compute_directions\u001b[0;34m(self, data, labels, hidden_layers, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    109\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirections, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigns, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolkit\u001b[38;5;241m.\u001b[39m_compute_directions(data, \n\u001b[1;32m    112\u001b[0m                                                    labels, \n\u001b[1;32m    113\u001b[0m                                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \n\u001b[1;32m    114\u001b[0m                                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer, \n\u001b[1;32m    115\u001b[0m                                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers, \n\u001b[1;32m    116\u001b[0m                                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparams,\n\u001b[1;32m    117\u001b[0m                                                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    118\u001b[0m                                                   )\n",
      "File \u001b[0;32m~/mech_interp/neural_control/control_toolkits.py:136\u001b[0m, in \u001b[0;36mRFMToolkit._compute_directions\u001b[0;34m(self, data, labels, model, tokenizer, hidden_layers, hyperparams, test_data, test_labels, component_idx, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m directions, signs, test_direction_accs, test_predictor_accs\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m directions, signs, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'signs' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "dataset = multi_concept_dataset(data_dir, concept_types, user_tag=user_tag, assistant_tag=assistant_tag)#, n_train=128)\n",
    "\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "\n",
    "language_controller = NeuralController(\n",
    "    language_model,\n",
    "    tokenizer,\n",
    "    rfm_iters=8,\n",
    "    batch_size=4,\n",
    "    control_method='rfm'\n",
    ")\n",
    "\n",
    "language_controller.compute_directions(train_data['inputs'], train_data['labels'],\n",
    "                                       log_path=f'../agop_spectra/multi_science', log_spectrum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf01a789-3998-4b7e-87e1-3acdd472478c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d0c8e-01fc-4419-aa10-de2510328d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_directions(poetry_dirs, harmful_dirs, a=0.5, b=0.5):\n",
    "    return {\n",
    "       k: a * poetry_dirs[k] + b * harmful_dirs[k]\n",
    "       for k in poetry_dirs.keys()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6a616b3-8ba6-43a8-b7d5-e8e66a093db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layers: [-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15, -16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "\n",
      "Controller hyperparameters:\n",
      "control_method       : rfm\n",
      "rfm_iters            : 8\n",
      "forward_batch_size   : 8\n",
      "M_batch_size         : 2048\n",
      "n_components         : 5\n",
      "\n",
      "Detector found\n"
     ]
    }
   ],
   "source": [
    "concept_type='english_shakespeare'\n",
    "poetry_controller = NeuralController(\n",
    "    language_model,\n",
    "    tokenizer,\n",
    "    control_method='rfm'\n",
    ")\n",
    "poetry_controller.load(concept=f'{concept_type}', model_name='llama_3_8b_it', path='../directions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "774a387d-ef81-4478-b311-a1a83dd30493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layers: [-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15, -16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "\n",
      "Controller hyperparameters:\n",
      "control_method       : rfm\n",
      "rfm_iters            : 8\n",
      "forward_batch_size   : 8\n",
      "M_batch_size         : 2048\n",
      "n_components         : 5\n",
      "\n",
      "Detector found\n",
      "Hidden layers: [-1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15, -16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "\n",
      "Controller hyperparameters:\n",
      "control_method       : rfm\n",
      "rfm_iters            : 8\n",
      "forward_batch_size   : 8\n",
      "M_batch_size         : 2048\n",
      "n_components         : 5\n",
      "\n",
      "Detector found\n"
     ]
    }
   ],
   "source": [
    "concept_types = ['Biology', 'Classical Mechanics']\n",
    "controllers = {}\n",
    "\n",
    "combine=False\n",
    "\n",
    "for concept_type in concept_types:\n",
    "    \n",
    "    controller = NeuralController(\n",
    "        language_model,\n",
    "        tokenizer,\n",
    "        control_method='rfm'\n",
    "    )\n",
    "    \n",
    "    other_type = [k for k in concept_types if k!=concept_type][0]\n",
    "    \n",
    "    controller.load(concept=f\"{concept_type.replace(' ', '-')}\", model_name='llama_3_8b_it', path='../directions/')\n",
    "    \n",
    "    if combine:\n",
    "        controller.directions = combine_directions(poetry_controller.directions, controller.directions, a=0.9, b=1.0)\n",
    "    controllers[concept_type] = controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6986ade2-2a13-4bc2-ad66-a11b4a048137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: \"<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is interesting about bird flight?<|eot_id|>\n",
      "===== + Classical Mechanics Control =====\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Bird flight is a most wondrous and subtle thing, full of mysteries and paradoxes. Here are some of the most interesting aspects of bird flight:\n",
      "\n",
      "1. **The Lifting Line**: The concept of the lifting line, introduced by Sir George Taylor, shows that a wing can produce lift without any net force on the wing itself. This is a most curious property, for it implies that the wing can produce lift without any net force on the wing, and yet, the wing must be subject to a net force to produce lift.\n",
      "\n",
      "2. **The Lifting Line Paradox**: The lifting line paradox, also known as the \"lifting line conundrum,\" arises when one considers the motion of a wing in a fluid, such as air. The paradox states that, if the wing is to produce lift, it must be subject to a net force, and yet, the\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concept = \"Biology\"\n",
    "concept = \"Classical Mechanics\"\n",
    "\n",
    "raw_inputs = [\n",
    "    # f\"What might someone who studies biology be interested in?\",\n",
    "    f\"What is interesting about bird flight?\",\n",
    "    # f\"What is interesting about oxygen?\",\n",
    "    # f\"What governs the movement of air in the respiratory system?\",\n",
    "]\n",
    "inputs = [controller.format_prompt(x) for x in raw_inputs]\n",
    "\n",
    "\n",
    "num_new_tokens = 180\n",
    "controller = controllers[concept]\n",
    "\n",
    "coef=0.4 #llama \n",
    "# coef=9\n",
    "\n",
    "layers = list(range(-1, -31, -1))\n",
    "# layers = list(range(-1, -41, -1))\n",
    "\n",
    "gens=[]\n",
    "print()\n",
    "for i in inputs:\n",
    "    print(\"Prompt:\", i)\n",
    "    # print(\"===== No Control =====\")\n",
    "    # print(controller.generate(i, max_new_tokens=num_new_tokens, do_sample=False).replace(i, \"\"))\n",
    "    # print()\n",
    "    \n",
    "    print(f\"===== + {concept} Control =====\")\n",
    "    gen = controller.generate(i, layers_to_control=layers, control_coef=coef, \n",
    "                                max_new_tokens=num_new_tokens, do_sample=False).replace(i, \"\")\n",
    "    gens.append(gen)\n",
    "    print(gen)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bad25-12d4-44ee-a848-988462c3d1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-daniel_jax]",
   "language": "python",
   "name": "conda-env-.conda-daniel_jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
